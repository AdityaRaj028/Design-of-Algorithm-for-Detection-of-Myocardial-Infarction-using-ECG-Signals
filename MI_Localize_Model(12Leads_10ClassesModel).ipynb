{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11g0wMJxAeXo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/Pdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_WQaFmvd_Uh",
        "outputId": "087e111d-abca-4915-bb08-4029964884aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Pdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the train and test data \n",
        "X_train = np.load('/content/Pdrive/MyDrive/BTP array files/XTrain.npy')\n",
        "X_test = np.load('/content/Pdrive/MyDrive/BTP array files/XTest.npy')\n",
        "y_train = np.load('/content/Pdrive/MyDrive/BTP array files/yTrain.npy')\n",
        "y_test = np.load('/content/Pdrive/MyDrive/BTP array files/yTest.npy')"
      ],
      "metadata": {
        "id": "jwDPRUvueUre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrQlArcbeu66",
        "outputId": "044ce3e7-e100-43fb-ea66-8d9633b2337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26490, 144, 1)\n",
            "(8830, 144, 1)\n",
            "(26490,)\n",
            "(8830,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n"
      ],
      "metadata": {
        "id": "lr7aOAVOfbNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmYG6u-9idG1",
        "outputId": "4e872273-f68e-47a9-aaee-d493d431b91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26490, 144)\n",
            "(8830, 144)\n",
            "(26490,)\n",
            "(8830,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary things for model-training.\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout, InputLayer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2 "
      ],
      "metadata": {
        "id": "dbFrTGcqe0Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    reg2 = l2(0.1)  # L2 regularizer\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape = (144,)))\n",
        "    model.add(Dense(units=50,activation=\"relu\", kernel_regularizer = reg2, bias_regularizer = reg2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=50,activation=\"relu\", kernel_regularizer = reg2, bias_regularizer = reg2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=24,activation=\"relu\", kernel_regularizer = reg2, bias_regularizer = reg2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Bi0LLS51e71z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3I1GeuNfDnO",
        "outputId": "8006b937-2ec0-492d-f5af-09bc48e99c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                7250      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 50)               200       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 50)               200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                1224      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 24)               96        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                250       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,770\n",
            "Trainable params: 11,522\n",
            "Non-trainable params: 248\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(x = X_train, y = y_train, batch_size = 256, epochs = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lopHsnRHfI0d",
        "outputId": "19b580f9-cab1-4cc8-d1c3-3a9830abe785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "104/104 [==============================] - 5s 6ms/step - loss: 17.3174 - accuracy: 0.1522\n",
            "Epoch 2/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 15.2480 - accuracy: 0.2627\n",
            "Epoch 3/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 13.5054 - accuracy: 0.3458\n",
            "Epoch 4/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 11.9598 - accuracy: 0.4176\n",
            "Epoch 5/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 10.5845 - accuracy: 0.4802\n",
            "Epoch 6/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 9.3665 - accuracy: 0.5282\n",
            "Epoch 7/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 8.2938 - accuracy: 0.5678\n",
            "Epoch 8/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 7.3504 - accuracy: 0.6008\n",
            "Epoch 9/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 6.5160 - accuracy: 0.6336\n",
            "Epoch 10/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 5.7857 - accuracy: 0.6604\n",
            "Epoch 11/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 5.1375 - accuracy: 0.6829\n",
            "Epoch 12/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 4.5672 - accuracy: 0.7032\n",
            "Epoch 13/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 4.0659 - accuracy: 0.7247\n",
            "Epoch 14/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 3.6262 - accuracy: 0.7442\n",
            "Epoch 15/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 3.2422 - accuracy: 0.7589\n",
            "Epoch 16/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.9041 - accuracy: 0.7759\n",
            "Epoch 17/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.6109 - accuracy: 0.7891\n",
            "Epoch 18/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.3540 - accuracy: 0.8023\n",
            "Epoch 19/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.1315 - accuracy: 0.8151\n",
            "Epoch 20/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.9332 - accuracy: 0.8268\n",
            "Epoch 21/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.7632 - accuracy: 0.8369\n",
            "Epoch 22/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.6132 - accuracy: 0.8468\n",
            "Epoch 23/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4794 - accuracy: 0.8558\n",
            "Epoch 24/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3669 - accuracy: 0.8631\n",
            "Epoch 25/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2663 - accuracy: 0.8702\n",
            "Epoch 26/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1768 - accuracy: 0.8751\n",
            "Epoch 27/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0990 - accuracy: 0.8815\n",
            "Epoch 28/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0280 - accuracy: 0.8856\n",
            "Epoch 29/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9689 - accuracy: 0.8911\n",
            "Epoch 30/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9129 - accuracy: 0.8969\n",
            "Epoch 31/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8636 - accuracy: 0.9009\n",
            "Epoch 32/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8211 - accuracy: 0.9045\n",
            "Epoch 33/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7785 - accuracy: 0.9092\n",
            "Epoch 34/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7415 - accuracy: 0.9129\n",
            "Epoch 35/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7084 - accuracy: 0.9165\n",
            "Epoch 36/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6790 - accuracy: 0.9181\n",
            "Epoch 37/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6539 - accuracy: 0.9227\n",
            "Epoch 38/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6281 - accuracy: 0.9236\n",
            "Epoch 39/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6056 - accuracy: 0.9273\n",
            "Epoch 40/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5806 - accuracy: 0.9310\n",
            "Epoch 41/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5626 - accuracy: 0.9316\n",
            "Epoch 42/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.9318\n",
            "Epoch 43/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.9338\n",
            "Epoch 44/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5135 - accuracy: 0.9371\n",
            "Epoch 45/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4984 - accuracy: 0.9387\n",
            "Epoch 46/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4887 - accuracy: 0.9381\n",
            "Epoch 47/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.9411\n",
            "Epoch 48/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4606 - accuracy: 0.9420\n",
            "Epoch 49/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4498 - accuracy: 0.9427\n",
            "Epoch 50/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4389 - accuracy: 0.9449\n",
            "Epoch 51/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.9450\n",
            "Epoch 52/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.9470\n",
            "Epoch 53/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4096 - accuracy: 0.9489\n",
            "Epoch 54/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.9500\n",
            "Epoch 55/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3944 - accuracy: 0.9500\n",
            "Epoch 56/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3840 - accuracy: 0.9508\n",
            "Epoch 57/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.9535\n",
            "Epoch 58/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3696 - accuracy: 0.9534\n",
            "Epoch 59/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3646 - accuracy: 0.9524\n",
            "Epoch 60/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3565 - accuracy: 0.9546\n",
            "Epoch 61/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3490 - accuracy: 0.9558\n",
            "Epoch 62/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3453 - accuracy: 0.9550\n",
            "Epoch 63/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3443 - accuracy: 0.9547\n",
            "Epoch 64/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3327 - accuracy: 0.9573\n",
            "Epoch 65/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3302 - accuracy: 0.9567\n",
            "Epoch 66/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3219 - accuracy: 0.9589\n",
            "Epoch 67/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3193 - accuracy: 0.9576\n",
            "Epoch 68/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3133 - accuracy: 0.9602\n",
            "Epoch 69/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3097 - accuracy: 0.9601\n",
            "Epoch 70/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3040 - accuracy: 0.9613\n",
            "Epoch 71/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3011 - accuracy: 0.9608\n",
            "Epoch 72/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2966 - accuracy: 0.9619\n",
            "Epoch 73/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2895 - accuracy: 0.9633\n",
            "Epoch 74/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2881 - accuracy: 0.9635\n",
            "Epoch 75/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2833 - accuracy: 0.9648\n",
            "Epoch 76/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2791 - accuracy: 0.9646\n",
            "Epoch 77/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2779 - accuracy: 0.9650\n",
            "Epoch 78/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2752 - accuracy: 0.9646\n",
            "Epoch 79/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2751 - accuracy: 0.9633\n",
            "Epoch 80/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.9648\n",
            "Epoch 81/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2654 - accuracy: 0.9662\n",
            "Epoch 82/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2615 - accuracy: 0.9663\n",
            "Epoch 83/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2579 - accuracy: 0.9676\n",
            "Epoch 84/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.9662\n",
            "Epoch 85/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2531 - accuracy: 0.9682\n",
            "Epoch 86/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2518 - accuracy: 0.9676\n",
            "Epoch 87/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2509 - accuracy: 0.9654\n",
            "Epoch 88/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2483 - accuracy: 0.9682\n",
            "Epoch 89/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2456 - accuracy: 0.9683\n",
            "Epoch 90/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2417 - accuracy: 0.9701\n",
            "Epoch 91/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2393 - accuracy: 0.9694\n",
            "Epoch 92/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2365 - accuracy: 0.9698\n",
            "Epoch 93/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2455 - accuracy: 0.9669\n",
            "Epoch 94/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9711\n",
            "Epoch 95/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2310 - accuracy: 0.9704\n",
            "Epoch 96/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2275 - accuracy: 0.9711\n",
            "Epoch 97/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2253 - accuracy: 0.9728\n",
            "Epoch 98/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2261 - accuracy: 0.9713\n",
            "Epoch 99/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2231 - accuracy: 0.9720\n",
            "Epoch 100/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2205 - accuracy: 0.9725\n",
            "Epoch 101/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2247 - accuracy: 0.9701\n",
            "Epoch 102/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9727\n",
            "Epoch 103/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2171 - accuracy: 0.9725\n",
            "Epoch 104/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2129 - accuracy: 0.9738\n",
            "Epoch 105/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2105 - accuracy: 0.9738\n",
            "Epoch 106/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2101 - accuracy: 0.9744\n",
            "Epoch 107/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2074 - accuracy: 0.9739\n",
            "Epoch 108/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2089 - accuracy: 0.9732\n",
            "Epoch 109/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9745\n",
            "Epoch 110/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9738\n",
            "Epoch 111/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1981 - accuracy: 0.9763\n",
            "Epoch 112/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9757\n",
            "Epoch 113/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.9738\n",
            "Epoch 114/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2012 - accuracy: 0.9739\n",
            "Epoch 115/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1984 - accuracy: 0.9749\n",
            "Epoch 116/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1966 - accuracy: 0.9749\n",
            "Epoch 117/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1956 - accuracy: 0.9744\n",
            "Epoch 118/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1977 - accuracy: 0.9735\n",
            "Epoch 119/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1978 - accuracy: 0.9737\n",
            "Epoch 120/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1970 - accuracy: 0.9734\n",
            "Epoch 121/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1919 - accuracy: 0.9743\n",
            "Epoch 122/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1879 - accuracy: 0.9777\n",
            "Epoch 123/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.9767\n",
            "Epoch 124/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1824 - accuracy: 0.9773\n",
            "Epoch 125/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1869 - accuracy: 0.9759\n",
            "Epoch 126/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1852 - accuracy: 0.9763\n",
            "Epoch 127/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9752\n",
            "Epoch 128/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1813 - accuracy: 0.9775\n",
            "Epoch 129/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9776\n",
            "Epoch 130/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9777\n",
            "Epoch 131/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9789\n",
            "Epoch 132/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9769\n",
            "Epoch 133/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9739\n",
            "Epoch 134/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9770\n",
            "Epoch 135/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1756 - accuracy: 0.9777\n",
            "Epoch 136/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9785\n",
            "Epoch 137/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1707 - accuracy: 0.9797\n",
            "Epoch 138/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9764\n",
            "Epoch 139/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1735 - accuracy: 0.9784\n",
            "Epoch 140/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1695 - accuracy: 0.9798\n",
            "Epoch 141/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9789\n",
            "Epoch 142/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1693 - accuracy: 0.9782\n",
            "Epoch 143/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9785\n",
            "Epoch 144/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1654 - accuracy: 0.9797\n",
            "Epoch 145/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1659 - accuracy: 0.9795\n",
            "Epoch 146/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1645 - accuracy: 0.9792\n",
            "Epoch 147/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1656 - accuracy: 0.9786\n",
            "Epoch 148/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1696 - accuracy: 0.9775\n",
            "Epoch 149/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1635 - accuracy: 0.9792\n",
            "Epoch 150/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1662 - accuracy: 0.9780\n",
            "Epoch 151/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9765\n",
            "Epoch 152/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9806\n",
            "Epoch 153/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1586 - accuracy: 0.9808\n",
            "Epoch 154/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1586 - accuracy: 0.9802\n",
            "Epoch 155/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1600 - accuracy: 0.9787\n",
            "Epoch 156/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9791\n",
            "Epoch 157/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.9773\n",
            "Epoch 158/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1582 - accuracy: 0.9790\n",
            "Epoch 159/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1524 - accuracy: 0.9817\n",
            "Epoch 160/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1519 - accuracy: 0.9821\n",
            "Epoch 161/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1551 - accuracy: 0.9805\n",
            "Epoch 162/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9809\n",
            "Epoch 163/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9816\n",
            "Epoch 164/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1550 - accuracy: 0.9807\n",
            "Epoch 165/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.9797\n",
            "Epoch 166/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9800\n",
            "Epoch 167/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.9813\n",
            "Epoch 168/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1486 - accuracy: 0.9818\n",
            "Epoch 169/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1520 - accuracy: 0.9796\n",
            "Epoch 170/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1551 - accuracy: 0.9796\n",
            "Epoch 171/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1479 - accuracy: 0.9823\n",
            "Epoch 172/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1540 - accuracy: 0.9796\n",
            "Epoch 173/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1491 - accuracy: 0.9816\n",
            "Epoch 174/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1443 - accuracy: 0.9829\n",
            "Epoch 175/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1496 - accuracy: 0.9814\n",
            "Epoch 176/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.9810\n",
            "Epoch 177/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1477 - accuracy: 0.9815\n",
            "Epoch 178/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1423 - accuracy: 0.9836\n",
            "Epoch 179/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1384 - accuracy: 0.9848\n",
            "Epoch 180/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1412 - accuracy: 0.9825\n",
            "Epoch 181/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1442 - accuracy: 0.9816\n",
            "Epoch 182/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1529 - accuracy: 0.9800\n",
            "Epoch 183/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1440 - accuracy: 0.9816\n",
            "Epoch 184/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1485 - accuracy: 0.9805\n",
            "Epoch 185/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1468 - accuracy: 0.9813\n",
            "Epoch 186/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1436 - accuracy: 0.9819\n",
            "Epoch 187/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1394 - accuracy: 0.9837\n",
            "Epoch 188/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1358 - accuracy: 0.9851\n",
            "Epoch 189/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1342 - accuracy: 0.9848\n",
            "Epoch 190/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1355 - accuracy: 0.9837\n",
            "Epoch 191/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1403 - accuracy: 0.9821\n",
            "Epoch 192/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9794\n",
            "Epoch 193/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1594 - accuracy: 0.9751\n",
            "Epoch 194/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1488 - accuracy: 0.9797\n",
            "Epoch 195/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1408 - accuracy: 0.9818\n",
            "Epoch 196/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9841\n",
            "Epoch 197/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1352 - accuracy: 0.9843\n",
            "Epoch 198/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1350 - accuracy: 0.9841\n",
            "Epoch 199/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1320 - accuracy: 0.9846\n",
            "Epoch 200/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1306 - accuracy: 0.9862\n",
            "Epoch 201/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1329 - accuracy: 0.9845\n",
            "Epoch 202/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1337 - accuracy: 0.9832\n",
            "Epoch 203/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1301 - accuracy: 0.9850\n",
            "Epoch 204/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1427 - accuracy: 0.9806\n",
            "Epoch 205/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1712 - accuracy: 0.9707\n",
            "Epoch 206/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1415 - accuracy: 0.9823\n",
            "Epoch 207/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1322 - accuracy: 0.9852\n",
            "Epoch 208/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1328 - accuracy: 0.9845\n",
            "Epoch 209/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1297 - accuracy: 0.9855\n",
            "Epoch 210/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9872\n",
            "Epoch 211/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1274 - accuracy: 0.9859\n",
            "Epoch 212/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1288 - accuracy: 0.9855\n",
            "Epoch 213/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1292 - accuracy: 0.9849\n",
            "Epoch 214/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1309 - accuracy: 0.9843\n",
            "Epoch 215/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1334 - accuracy: 0.9838\n",
            "Epoch 216/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1437 - accuracy: 0.9788\n",
            "Epoch 217/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1373 - accuracy: 0.9812\n",
            "Epoch 218/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1297 - accuracy: 0.9846\n",
            "Epoch 219/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1280 - accuracy: 0.9851\n",
            "Epoch 220/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1295 - accuracy: 0.9843\n",
            "Epoch 221/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1293 - accuracy: 0.9843\n",
            "Epoch 222/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1256 - accuracy: 0.9853\n",
            "Epoch 223/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1344 - accuracy: 0.9833\n",
            "Epoch 224/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1315 - accuracy: 0.9832\n",
            "Epoch 225/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1258 - accuracy: 0.9853\n",
            "Epoch 226/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1249 - accuracy: 0.9863\n",
            "Epoch 227/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9851\n",
            "Epoch 228/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1225 - accuracy: 0.9867\n",
            "Epoch 229/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9773\n",
            "Epoch 230/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1323 - accuracy: 0.9827\n",
            "Epoch 231/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1318 - accuracy: 0.9828\n",
            "Epoch 232/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9852\n",
            "Epoch 233/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9876\n",
            "Epoch 234/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1243 - accuracy: 0.9854\n",
            "Epoch 235/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1244 - accuracy: 0.9855\n",
            "Epoch 236/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1289 - accuracy: 0.9841\n",
            "Epoch 237/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1282 - accuracy: 0.9843\n",
            "Epoch 238/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1219 - accuracy: 0.9861\n",
            "Epoch 239/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1205 - accuracy: 0.9867\n",
            "Epoch 240/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9863\n",
            "Epoch 241/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.9871\n",
            "Epoch 242/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1221 - accuracy: 0.9851\n",
            "Epoch 243/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1261 - accuracy: 0.9837\n",
            "Epoch 244/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1234 - accuracy: 0.9853\n",
            "Epoch 245/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1320 - accuracy: 0.9818\n",
            "Epoch 246/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1448 - accuracy: 0.9764\n",
            "Epoch 247/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1239 - accuracy: 0.9862\n",
            "Epoch 248/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1199 - accuracy: 0.9866\n",
            "Epoch 249/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1154 - accuracy: 0.9880\n",
            "Epoch 250/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1141 - accuracy: 0.9882\n",
            "Epoch 251/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1125 - accuracy: 0.9883\n",
            "Epoch 252/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1147 - accuracy: 0.9878\n",
            "Epoch 253/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1169 - accuracy: 0.9872\n",
            "Epoch 254/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1122 - accuracy: 0.9882\n",
            "Epoch 255/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1169 - accuracy: 0.9864\n",
            "Epoch 256/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1307 - accuracy: 0.9812\n",
            "Epoch 257/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1342 - accuracy: 0.9808\n",
            "Epoch 258/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1236 - accuracy: 0.9840\n",
            "Epoch 259/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1250 - accuracy: 0.9833\n",
            "Epoch 260/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1212 - accuracy: 0.9852\n",
            "Epoch 261/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1159 - accuracy: 0.9871\n",
            "Epoch 262/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1106 - accuracy: 0.9895\n",
            "Epoch 263/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1122 - accuracy: 0.9883\n",
            "Epoch 264/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1103 - accuracy: 0.9886\n",
            "Epoch 265/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1116 - accuracy: 0.9892\n",
            "Epoch 266/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1253 - accuracy: 0.9830\n",
            "Epoch 267/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1220 - accuracy: 0.9838\n",
            "Epoch 268/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1134 - accuracy: 0.9879\n",
            "Epoch 269/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9881\n",
            "Epoch 270/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9851\n",
            "Epoch 271/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1495 - accuracy: 0.9744\n",
            "Epoch 272/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1225 - accuracy: 0.9841\n",
            "Epoch 273/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1131 - accuracy: 0.9883\n",
            "Epoch 274/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1149 - accuracy: 0.9866\n",
            "Epoch 275/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1092 - accuracy: 0.9887\n",
            "Epoch 276/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1069 - accuracy: 0.9898\n",
            "Epoch 277/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1092 - accuracy: 0.9891\n",
            "Epoch 278/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1074 - accuracy: 0.9892\n",
            "Epoch 279/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1143 - accuracy: 0.9864\n",
            "Epoch 280/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1292 - accuracy: 0.9816\n",
            "Epoch 281/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1289 - accuracy: 0.9811\n",
            "Epoch 282/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1209 - accuracy: 0.9842\n",
            "Epoch 283/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1143 - accuracy: 0.9873\n",
            "Epoch 284/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9902\n",
            "Epoch 285/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1070 - accuracy: 0.9896\n",
            "Epoch 286/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1070 - accuracy: 0.9891\n",
            "Epoch 287/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1103 - accuracy: 0.9887\n",
            "Epoch 288/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9884\n",
            "Epoch 289/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1191 - accuracy: 0.9848\n",
            "Epoch 290/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1307 - accuracy: 0.9812\n",
            "Epoch 291/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1227 - accuracy: 0.9835\n",
            "Epoch 292/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1155 - accuracy: 0.9863\n",
            "Epoch 293/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1119 - accuracy: 0.9875\n",
            "Epoch 294/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1205 - accuracy: 0.9846\n",
            "Epoch 295/300\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1209 - accuracy: 0.9840\n",
            "Epoch 296/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 0.9895\n",
            "Epoch 297/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9895\n",
            "Epoch 298/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1082 - accuracy: 0.9892\n",
            "Epoch 299/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1054 - accuracy: 0.9895\n",
            "Epoch 300/300\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1071 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef90126090>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size = 256)"
      ],
      "metadata": {
        "id": "MsTv6-FaIWLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a27f83-4a79-4a85-c728-ac3ada8ef4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.9467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", round(score[1]*100, 2))"
      ],
      "metadata": {
        "id": "CXwZaOC9J9Vz",
        "outputId": "fbaa6d5e-5fd8-4b16-a28b-6ec0b7e86a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  94.67\n"
          ]
        }
      ]
    }
  ]
}